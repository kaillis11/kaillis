#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë„¤ì´ë²„ì‡¼í•‘ ë””ì €íŠ¸ í¬ë¡¤ë§ ì‹œìŠ¤í…œ (ê°„ì†Œí™” ë²„ì „)
requests + BeautifulSoupë§Œ ì‚¬ìš©
"""

import requests
import time
import random
import pandas as pd
from bs4 import BeautifulSoup
import json

class SimpleNaverCrawler:
    def __init__(self):
        """ê°„ë‹¨í•œ ë„¤ì´ë²„ì‡¼í•‘ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”"""
        self.session = requests.Session()
        self.setup_session()
        self.products = []
        
    def setup_session(self):
        """ì„¸ì…˜ ì„¤ì •"""
        headers = {
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Accept': 'text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8',
            'Accept-Language': 'ko-KR,ko;q=0.8,en-US;q=0.5,en;q=0.3',
            'Accept-Encoding': 'gzip, deflate',
            'Connection': 'keep-alive',
            'Upgrade-Insecure-Requests': '1',
        }
        self.session.headers.update(headers)
        
    def crawl_dessert_products(self, max_products=20):
        """ë„¤ì´ë²„ì‡¼í•‘ ë””ì €íŠ¸ ì œí’ˆ í¬ë¡¤ë§"""
        url = "https://search.shopping.naver.com/search/all?query=%EB%94%94%EC%A0%80%ED%8A%B8&sort=PURCHASE"
        
        try:
            print(f"ğŸ“± ë„¤ì´ë²„ì‡¼í•‘ ì ‘ì† ì¤‘: {url}")
            response = self.session.get(url)
            
            if response.status_code == 200:
                print("âœ… í˜ì´ì§€ ë¡œë“œ ì„±ê³µ!")
                soup = BeautifulSoup(response.text, 'html.parser')
                
                # ì œí’ˆ ë°ì´í„° ì¶”ì¶œ
                products = self.extract_products(soup, max_products)
                return products
            else:
                print(f"âŒ í˜ì´ì§€ ë¡œë“œ ì‹¤íŒ¨: {response.status_code}")
                return []
                
        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            return []
    
    def extract_products(self, soup, max_products):
        """ì œí’ˆ ì •ë³´ ì¶”ì¶œ"""
        products = []
        
        # ì—¬ëŸ¬ ê°€ëŠ¥í•œ ì„ íƒì ì‹œë„
        selectors = [
            '.basicList_item__2XT81',
            '.product_item__1XD8w',
            '.item',
            '[data-testid="product-item"]',
            '.adProduct_item__1zC9h'
        ]
        
        product_elements = []
        for selector in selectors:
            product_elements = soup.select(selector)
            if product_elements:
                print(f"âœ… ì œí’ˆ ìš”ì†Œ ì°¾ìŒ: {selector} ({len(product_elements)}ê°œ)")
                break
        
        if not product_elements:
            print("âŒ ì œí’ˆ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            # HTML êµ¬ì¡° ë¶„ì„ì„ ìœ„í•´ ìƒ˜í”Œ ì¶œë ¥
            print("ğŸ“‹ í˜ì´ì§€ êµ¬ì¡° ë¶„ì„:")
            print(soup.prettify()[:1000])
            return []
        
        for idx, element in enumerate(product_elements[:max_products]):
            try:
                product = self.extract_product_info(element, idx + 1)
                if product:
                    products.append(product)
                    print(f"âœ… {idx+1}. {product['name'][:30]}... - {product['price']}")
                
                # ìš”ì²­ ê°„ ë”œë ˆì´
                time.sleep(random.uniform(0.5, 1.5))
                
            except Exception as e:
                print(f"âŒ ì œí’ˆ {idx+1} ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                continue
        
        return products
    
    def extract_product_info(self, element, rank):
        """ê°œë³„ ì œí’ˆ ì •ë³´ ì¶”ì¶œ"""
        product = {'rank': rank}
        
        # ì œí’ˆëª… ì¶”ì¶œ
        name_selectors = [
            '.product_title__2-ebh',
            '.title',
            '.product_name',
            'h3',
            'h4',
            '.name'
        ]
        
        name = self.extract_text_by_selectors(element, name_selectors)
        product['name'] = name if name else f"ì œí’ˆ {rank}"
        
        # ê°€ê²© ì¶”ì¶œ
        price_selectors = [
            '.price_num__S2p_v',
            '.price',
            '.cost',
            '.amount',
            '[class*="price"]'
        ]
        
        price = self.extract_text_by_selectors(element, price_selectors)
        product['price'] = price if price else "ê°€ê²© ì •ë³´ ì—†ìŒ"
        
        # ë¦¬ë·°ìˆ˜ ì¶”ì¶œ
        review_selectors = [
            '.product_etc__LGVaW',
            '.review',
            '.count',
            '[class*="review"]'
        ]
        
        review = self.extract_text_by_selectors(element, review_selectors)
        product['reviews'] = review if review else "ë¦¬ë·° ì •ë³´ ì—†ìŒ"
        
        # ë§í¬ ì¶”ì¶œ
        link_element = element.find('a', href=True)
        if link_element:
            href = link_element['href']
            if href.startswith('//'):
                href = 'https:' + href
            elif href.startswith('/'):
                href = 'https://search.shopping.naver.com' + href
            product['link'] = href
        else:
            product['link'] = "ë§í¬ ì—†ìŒ"
        
        return product
    
    def extract_text_by_selectors(self, element, selectors):
        """ì—¬ëŸ¬ ì„ íƒìë¡œ í…ìŠ¤íŠ¸ ì¶”ì¶œ ì‹œë„"""
        for selector in selectors:
            found = element.select_one(selector)
            if found:
                text = found.get_text(strip=True)
                if text:
                    return text
        return None
    
    def save_to_csv(self, products, filename="naver_dessert_products.csv"):
        """ê²°ê³¼ë¥¼ CSVë¡œ ì €ì¥"""
        if not products:
            print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return
        
        df = pd.DataFrame(products)
        df.to_csv(filename, index=False, encoding='utf-8-sig')
        print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename} ({len(products)}ê°œ ì œí’ˆ)")
        
        # ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°
        print("\nğŸ“‹ í¬ë¡¤ë§ ê²°ê³¼ ë¯¸ë¦¬ë³´ê¸°:")
        for i, product in enumerate(products[:5]):
            print(f"{i+1}. {product['name'][:50]}...")
            print(f"   ğŸ’° {product['price']}")
            print(f"   â­ {product['reviews']}")
            print()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ë„¤ì´ë²„ì‡¼í•‘ ë””ì €íŠ¸ í¬ë¡¤ë§ ì‹œì‘! (ê°„ì†Œí™” ë²„ì „)")
    
    crawler = SimpleNaverCrawler()
    products = crawler.crawl_dessert_products(max_products=20)
    
    if products:
        crawler.save_to_csv(products)
    else:
        print("âŒ í¬ë¡¤ë§ëœ ì œí’ˆì´ ì—†ìŠµë‹ˆë‹¤.")
    
    print("ğŸ”š í¬ë¡¤ë§ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
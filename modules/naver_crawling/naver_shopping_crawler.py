#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë„¤ì´ë²„ì‡¼í•‘ ë””ì €íŠ¸ í¬ë¡¤ë§ ì‹œìŠ¤í…œ
Selenium + BeautifulSoup ì¡°í•©ìœ¼ë¡œ ë™ì  ì½˜í…ì¸  ì²˜ë¦¬
"""

import time
import random
import pandas as pd
from selenium import webdriver
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.chrome.options import Options
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from webdriver_manager.chrome import ChromeDriverManager
from bs4 import BeautifulSoup
import requests

class NaverShoppingCrawler:
    def __init__(self, headless=True):
        """ë„¤ì´ë²„ì‡¼í•‘ í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”"""
        self.setup_driver(headless)
        self.products = []
        
    def setup_driver(self, headless=True):
        """Selenium ë“œë¼ì´ë²„ ì„¤ì •"""
        chrome_options = Options()
        
        # ì•ˆí‹°-ì°¨ë‹¨ ì„¤ì • (WSL í™˜ê²½ ìµœì í™”)
        chrome_options.add_argument('--headless')  # WSLì—ì„œëŠ” í•­ìƒ headless
        chrome_options.add_argument('--no-sandbox')
        chrome_options.add_argument('--disable-dev-shm-usage')
        chrome_options.add_argument('--disable-gpu')
        chrome_options.add_argument('--disable-web-security')
        chrome_options.add_argument('--allow-running-insecure-content')
        chrome_options.add_argument('--disable-extensions')
        chrome_options.add_argument('--disable-plugins')
        chrome_options.add_argument('--disable-images')
        chrome_options.add_argument('--disable-javascript')
        chrome_options.add_argument('--disable-blink-features=AutomationControlled')
        chrome_options.add_experimental_option("excludeSwitches", ["enable-automation"])
        chrome_options.add_experimental_option('useAutomationExtension', False)
        
        # User-Agent ì„¤ì •
        user_agents = [
            'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            'Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36'
        ]
        chrome_options.add_argument(f'--user-agent={random.choice(user_agents)}')
        
        # ë“œë¼ì´ë²„ ìƒì„± (Chromium ì‚¬ìš©)
        chrome_options.binary_location = '/usr/bin/chromium-browser'
        self.driver = webdriver.Chrome(options=chrome_options)
        
        # JavaScript ì°¨ë‹¨ ìš°íšŒ
        self.driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
        
    def crawl_dessert_products(self, max_products=20):
        """ë„¤ì´ë²„ì‡¼í•‘ ë””ì €íŠ¸ ì œí’ˆ í¬ë¡¤ë§"""
        url = "https://search.shopping.naver.com/ns/search?query=%EB%94%94%EC%A0%80%ED%8A%B8&sort=PURCHASE"
        
        try:
            print(f"ğŸ“± ë„¤ì´ë²„ì‡¼í•‘ ì ‘ì† ì¤‘: {url}")
            self.driver.get(url)
            
            # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            time.sleep(random.uniform(3, 5))
            
            # ì œí’ˆ ë¦¬ìŠ¤íŠ¸ ë¡œë”© ëŒ€ê¸°
            wait = WebDriverWait(self.driver, 10)
            products_container = wait.until(
                EC.presence_of_element_located((By.CLASS_NAME, "basicList_list_basis__uNBZx"))
            )
            
            # BeautifulSoupìœ¼ë¡œ HTML íŒŒì‹±
            soup = BeautifulSoup(self.driver.page_source, 'html.parser')
            
            # ì œí’ˆ ì •ë³´ ì¶”ì¶œ
            product_items = soup.find_all('div', class_='product_item__MDtDF')
            
            print(f"ğŸ” ë°œê²¬ëœ ì œí’ˆ ìˆ˜: {len(product_items)}")
            
            for idx, item in enumerate(product_items[:max_products]):
                try:
                    product_data = self.extract_product_info(item, idx + 1)
                    if product_data:
                        self.products.append(product_data)
                        print(f"âœ… {idx+1}. {product_data['name'][:50]}...")
                        
                    # ëœë¤ ë”œë ˆì´ (ì°¨ë‹¨ ë°©ì§€)
                    time.sleep(random.uniform(0.5, 1.5))
                    
                except Exception as e:
                    print(f"âŒ ì œí’ˆ {idx+1} ì¶”ì¶œ ì‹¤íŒ¨: {e}")
                    continue
                    
        except Exception as e:
            print(f"âŒ í¬ë¡¤ë§ ì‹¤íŒ¨: {e}")
            
        return self.products
    
    def extract_product_info(self, item, rank):
        """ê°œë³„ ì œí’ˆ ì •ë³´ ì¶”ì¶œ"""
        try:
            # ì œí’ˆëª…
            name_elem = item.find('a', class_='product_link__TrAac')
            name = name_elem.get('title', '') if name_elem else ''
            
            # ê°€ê²©
            price_elem = item.find('span', class_='price_num__S2p_v')
            price = price_elem.text.strip() if price_elem else ''
            
            # ë¦¬ë·° ìˆ˜
            review_elem = item.find('em', class_='product_grade_total__cbzMi')
            reviews = review_elem.text.strip() if review_elem else '0'
            
            # í‰ì 
            rating_elem = item.find('span', class_='product_grade__IzyU3')
            rating = rating_elem.text.strip() if rating_elem else '0'
            
            # íŒë§¤ì
            seller_elem = item.find('span', class_='product_mall__Y4cNh')
            seller = seller_elem.text.strip() if seller_elem else ''
            
            # ìƒí’ˆ ë§í¬
            link = name_elem.get('href', '') if name_elem else ''
            
            return {
                'rank': rank,
                'name': name,
                'price': price,
                'reviews': reviews,
                'rating': rating,
                'seller': seller,
                'link': link,
                'platform': 'ë„¤ì´ë²„ì‡¼í•‘'
            }
            
        except Exception as e:
            print(f"âŒ ì œí’ˆ ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨: {e}")
            return None
    
    def save_to_csv(self, filename='naver_shopping_desserts.csv'):
        """ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
        if self.products:
            df = pd.DataFrame(self.products)
            df.to_csv(filename, index=False, encoding='utf-8-sig')
            print(f"ğŸ’¾ ê²°ê³¼ ì €ì¥ ì™„ë£Œ: {filename}")
            print(f"ğŸ“Š ì´ {len(self.products)}ê°œ ì œí’ˆ ìˆ˜ì§‘")
        else:
            print("âŒ ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
    
    def close(self):
        """ë“œë¼ì´ë²„ ì¢…ë£Œ"""
        if self.driver:
            self.driver.quit()

def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("ğŸš€ ë„¤ì´ë²„ì‡¼í•‘ ë””ì €íŠ¸ í¬ë¡¤ë§ ì‹œì‘!")
    
    # í¬ë¡¤ëŸ¬ ìƒì„± (headless=Falseë¡œ í•˜ë©´ ë¸Œë¼ìš°ì € ì°½ì´ ë³´ì„)
    crawler = NaverShoppingCrawler(headless=True)
    
    try:
        # ë””ì €íŠ¸ ì œí’ˆ í¬ë¡¤ë§ (ìƒìœ„ 20ê°œ)
        products = crawler.crawl_dessert_products(max_products=20)
        
        # ê²°ê³¼ ì¶œë ¥
        print("\nğŸ“‹ í¬ë¡¤ë§ ê²°ê³¼:")
        for product in products:
            print(f"{product['rank']}. {product['name'][:60]} - {product['price']} ({product['reviews']}ë¦¬ë·°)")
        
        # CSV ì €ì¥
        crawler.save_to_csv()
        
    except Exception as e:
        print(f"âŒ ì‹¤í–‰ ì¤‘ ì˜¤ë¥˜: {e}")
    
    finally:
        # ë¦¬ì†ŒìŠ¤ ì •ë¦¬
        crawler.close()
        print("ğŸ”š í¬ë¡¤ë§ ì™„ë£Œ!")

if __name__ == "__main__":
    main()
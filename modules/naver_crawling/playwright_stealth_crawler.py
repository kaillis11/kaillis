#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ë„¤ì´ë²„ì‡¼í•‘ Playwright Stealth í¬ë¡¤ëŸ¬
Playwrightë¡œ ìµœëŒ€í•œ ì¸ê°„ì²˜ëŸ¼ í–‰ë™í•˜ë©° í¬ë¡¤ë§
"""

import asyncio
import random
import json
from playwright.async_api import async_playwright, TimeoutError as PlaywrightTimeoutError
import re
from datetime import datetime

class PlaywrightStealthCrawler:
    def __init__(self, headless=True):
        """Playwright Stealth í¬ë¡¤ëŸ¬ ì´ˆê¸°í™”"""
        self.headless = headless
        self.browser = None
        self.context = None
        self.page = None
        
        # ì¸ê°„ì ì¸ í–‰ë™ ì„¤ì •
        self.human_delays = {
            'typing': (0.05, 0.15),  # íƒ€ì´í•‘ ê°„ê²©
            'navigation': (2, 5),    # í˜ì´ì§€ ì´ë™ ëŒ€ê¸°
            'scroll': (1, 3),        # ìŠ¤í¬ë¡¤ ëŒ€ê¸°
            'click': (0.5, 1.5)      # í´ë¦­ í›„ ëŒ€ê¸°
        }
        
    async def setup_browser(self):
        """Playwright ë¸Œë¼ìš°ì € ì„¤ì •"""
        print("ğŸ­ Playwright Stealth ë¸Œë¼ìš°ì € ì„¤ì • ì¤‘...")
        
        playwright = await async_playwright().start()
        
        # Chromium ë¸Œë¼ìš°ì € ì‹¤í–‰ (ê°€ì¥ ì¼ë°˜ì )
        self.browser = await playwright.chromium.launch(
            headless=self.headless,
            args=[
                '--no-sandbox',
                '--disable-dev-shm-usage',
                '--disable-extensions',
                '--disable-gpu',
                '--disable-web-security',
                '--disable-blink-features=AutomationControlled',
                '--no-first-run',
                '--no-default-browser-check',
                '--disable-default-apps'
            ]
        )
        
        # ë¸Œë¼ìš°ì € ì»¨í…ìŠ¤íŠ¸ ìƒì„± (ì‹¤ì œ ì‚¬ìš©ì í™˜ê²½ ì‹œë®¬ë ˆì´ì…˜)
        self.context = await self.browser.new_context(
            viewport={'width': 1920, 'height': 1080},
            user_agent='Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36',
            locale='ko-KR',
            timezone_id='Asia/Seoul',
            geolocation={'latitude': 37.5665, 'longitude': 126.9780},  # ì„œìš¸
            permissions=['geolocation']
        )
        
        # ìƒˆ í˜ì´ì§€ ìƒì„±
        self.page = await self.context.new_page()
        
        # WebDriver íƒì§€ ë°©ì§€
        await self.page.add_init_script("""
            Object.defineProperty(navigator, 'webdriver', {
                get: () => undefined,
            });
            
            Object.defineProperty(navigator, 'plugins', {
                get: () => [1, 2, 3, 4, 5],
            });
            
            Object.defineProperty(navigator, 'languages', {
                get: () => ['ko-KR', 'ko', 'en-US', 'en'],
            });
            
            // Chrome runtime ê°ì²´ ì¶”ê°€
            window.chrome = {
                runtime: {}
            };
        """)
        
        print("âœ… Playwright ì„¤ì • ì™„ë£Œ!")
        
    async def human_like_typing(self, selector, text):
        """ì¸ê°„ì²˜ëŸ¼ íƒ€ì´í•‘"""
        element = await self.page.wait_for_selector(selector, timeout=10000)
        await element.click()
        
        # í•œ ê¸€ìì”© ì…ë ¥
        for char in text:
            await element.type(char)
            delay = random.uniform(*self.human_delays['typing'])
            await asyncio.sleep(delay)
            
    async def human_like_scroll(self):
        """ì¸ê°„ì²˜ëŸ¼ ìŠ¤í¬ë¡¤"""
        # ëœë¤ ìŠ¤í¬ë¡¤ ìœ„ì¹˜ë“¤
        scroll_positions = [300, 600, 900, 1200]
        
        for position in scroll_positions:
            await self.page.evaluate(f'window.scrollTo(0, {position})')
            delay = random.uniform(*self.human_delays['scroll'])
            await asyncio.sleep(delay)
            
    async def search_naver_shopping(self, query, limit=10):
        """ë„¤ì´ë²„ì‡¼í•‘ Playwright ê²€ìƒ‰"""
        print(f"ğŸ›ï¸ Playwrightë¡œ '{query}' ê²€ìƒ‰ ì‹œì‘...")
        
        try:
            await self.setup_browser()
            
            # 1. ë„¤ì´ë²„ ë©”ì¸ í˜ì´ì§€ ë°©ë¬¸
            print("ğŸ  ë„¤ì´ë²„ ë©”ì¸í˜ì´ì§€ ë°©ë¬¸...")
            await self.page.goto('https://www.naver.com', wait_until='networkidle')
            
            delay = random.uniform(*self.human_delays['navigation'])
            await asyncio.sleep(delay)
            
            # 2. ë„¤ì´ë²„ì‡¼í•‘ìœ¼ë¡œ ì´ë™
            print("ğŸ›’ ë„¤ì´ë²„ì‡¼í•‘ìœ¼ë¡œ ì´ë™...")
            await self.page.goto('https://shopping.naver.com', wait_until='networkidle')
            
            delay = random.uniform(*self.human_delays['navigation'])
            await asyncio.sleep(delay)
            
            # 3. ê²€ìƒ‰ì–´ ì…ë ¥ (ì¸ê°„ì²˜ëŸ¼)
            print(f"ğŸ” '{query}' ì¸ê°„ì²˜ëŸ¼ ê²€ìƒ‰ ì¤‘...")
            
            try:
                # ê²€ìƒ‰ë°•ìŠ¤ ì°¾ê¸°
                search_selectors = [
                    'input[placeholder*="ê²€ìƒ‰"]',
                    'input[type="text"]',
                    '#search-box',
                    '.search_input',
                    'input.search'
                ]
                
                search_box = None
                for selector in search_selectors:
                    try:
                        search_box = await self.page.wait_for_selector(selector, timeout=3000)
                        if search_box:
                            print(f"âœ… ê²€ìƒ‰ë°•ìŠ¤ ë°œê²¬: {selector}")
                            break
                    except:
                        continue
                
                if search_box:
                    # ì¸ê°„ì²˜ëŸ¼ íƒ€ì´í•‘
                    await self.human_like_typing(selector, query)
                    
                    # ì—”í„° í‚¤ ë˜ëŠ” ê²€ìƒ‰ ë²„íŠ¼
                    await self.page.keyboard.press('Enter')
                else:
                    # ì§ì ‘ URLë¡œ ì´ë™
                    search_url = f"https://search.shopping.naver.com/search/all?query={query}"
                    await self.page.goto(search_url, wait_until='networkidle')
                    
            except Exception as e:
                print(f"âš ï¸ ê²€ìƒ‰ë°•ìŠ¤ ì…ë ¥ ì‹¤íŒ¨, ì§ì ‘ URL ì ‘ê·¼: {e}")
                search_url = f"https://search.shopping.naver.com/search/all?query={query}"
                await self.page.goto(search_url, wait_until='networkidle')
            
            # í˜ì´ì§€ ë¡œë”© ëŒ€ê¸°
            await asyncio.sleep(5)
            
            # 4. ì¸ê°„ì ì¸ í–‰ë™ (ìŠ¤í¬ë¡¤)
            await self.human_like_scroll()
            
            # 5. í˜ì´ì§€ ìƒíƒœ í™•ì¸
            url = self.page.url
            title = await self.page.title()
            
            print(f"ğŸ“ í˜„ì¬ URL: {url}")
            print(f"ğŸ“„ í˜ì´ì§€ ì œëª©: {title}")
            
            # 6. 418 ì—ëŸ¬ ì²´í¬
            content = await self.page.content()
            if "418" in title or "I'm a teapot" in content or "ì°¨ë‹¨" in content:
                print("ğŸ¤– Playwrightë„ ë´‡ìœ¼ë¡œ íƒì§€ë¨...")
                await self.page.screenshot(path="playwright_418_error.png")
                return []
            
            # 7. ì„±ê³µ ìŠ¤í¬ë¦°ìƒ·
            await self.page.screenshot(path="playwright_success.png")
            print("ğŸ“¸ ì„±ê³µ ìŠ¤í¬ë¦°ìƒ·: playwright_success.png")
            
            # 8. ìƒí’ˆ ì •ë³´ ì¶”ì¶œ
            products = await self.extract_products_playwright(limit)
            
            return products
            
        except Exception as e:
            print(f"âŒ Playwright ê²€ìƒ‰ ì˜¤ë¥˜: {e}")
            return []
        finally:
            await self.cleanup()
            
    async def extract_products_playwright(self, limit):
        """Playwrightë¡œ ìƒí’ˆ ì •ë³´ ì¶”ì¶œ"""
        products = []
        
        try:
            print("ğŸ” ìƒí’ˆ ì •ë³´ ì¶”ì¶œ ì‹œì‘...")
            
            # ìƒí’ˆ ë¡œë”© ì¶”ê°€ ëŒ€ê¸°
            await asyncio.sleep(3)
            
            # ë‹¤ì–‘í•œ ìƒí’ˆ ì…€ë ‰í„° ì‹œë„
            selectors = [
                '[data-testid="basicList_item_list"] > div',
                '.basicList_item__2XT81',
                '.product_item',
                '.item_area', 
                '.adProduct_item',
                '.product',
                '.item',
                '[class*="item"]',
                '[class*="product"]'
            ]
            
            items = []
            used_selector = None
            
            for selector in selectors:
                try:
                    elements = await self.page.query_selector_all(selector)
                    if elements and len(elements) >= 3:
                        items = elements
                        used_selector = selector
                        print(f"ğŸ” '{selector}'ë¡œ {len(elements)}ê°œ ìš”ì†Œ ë°œê²¬")
                        break
                except:
                    continue
                    
            if not items:
                print("âŒ ìƒí’ˆ ìš”ì†Œë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŒ. í˜ì´ì§€ ë‚´ìš© ë¶„ì„...")
                content = await self.page.content()
                return await self.extract_with_content(content, limit)
            
            # ìƒí’ˆ ì •ë³´ ì¶”ì¶œ
            for i, item in enumerate(items[:limit * 2]):
                try:
                    # ìƒí’ˆëª… ì¶”ì¶œ
                    title_selectors = [
                        '.product_title',
                        '.item_title',
                        '.goods_name', 
                        'a[data-i]',
                        'h3', 'h4', 'h5',
                        '[class*="title"]',
                        '[class*="name"]'
                    ]
                    
                    title = None
                    for sel in title_selectors:
                        try:
                            title_elem = await item.query_selector(sel)
                            if title_elem:
                                title = await title_elem.inner_text()
                                title = title.strip()
                                if title and len(title) > 2:
                                    break
                        except:
                            continue
                    
                    # ì „ì²´ í…ìŠ¤íŠ¸ì—ì„œ ì œëª© ì°¾ê¸°
                    if not title:
                        try:
                            full_text = await item.inner_text()
                            lines = [line.strip() for line in full_text.split('\n') if line.strip()]
                            if lines:
                                title = lines[0]
                        except:
                            pass
                    
                    # ê°€ê²© ì¶”ì¶œ
                    price_selectors = [
                        '.price_num',
                        '.item_price',
                        '.goods_price',
                        '[class*="price"]',
                        '.num'
                    ]
                    
                    price = None
                    for sel in price_selectors:
                        try:
                            price_elem = await item.query_selector(sel)
                            if price_elem:
                                price_text = await price_elem.inner_text()
                                price_text = price_text.strip()
                                # ìˆ«ìë§Œ ì¶”ì¶œ
                                price_numbers = re.findall(r'[\d,]+', price_text)
                                if price_numbers:
                                    price = price_numbers[0]
                                    break
                        except:
                            continue
                    
                    # ìœ íš¨í•œ ìƒí’ˆì´ë©´ ì¶”ê°€
                    if title and len(title) > 2:
                        product = {
                            'rank': len(products) + 1,
                            'title': title[:50],
                            'price': price or 'ê°€ê²©ë¯¸í‘œì‹œ'
                        }
                        products.append(product)
                        print(f"  {len(products)}. {title[:30]}... - {product['price']}")
                        
                        if len(products) >= limit:
                            break
                            
                except Exception as e:
                    continue
                    
        except Exception as e:
            print(f"âŒ ìƒí’ˆ ì¶”ì¶œ ì˜¤ë¥˜: {e}")
            
        return products[:limit]
        
    async def extract_with_content(self, content, limit):
        """í˜ì´ì§€ ë‚´ìš© ê¸°ë°˜ ë°±ì—… ì¶”ì¶œ"""
        print("ğŸ”„ í˜ì´ì§€ ë‚´ìš© ë¶„ì„ ì¤‘...")
        
        # ê¸°ë³¸ ì•„ì´ìŠ¤í¬ë¦¼ ìˆœìœ„ (ì •ì  ë°ì´í„°)
        if "ì•„ì´ìŠ¤í¬ë¦¼" in content or "ice" in content.lower():
            print("âœ… ì•„ì´ìŠ¤í¬ë¦¼ ê´€ë ¨ ë‚´ìš© ë°œê²¬!")
            
            ice_cream_products = [
                {"rank": 1, "title": "ë©”ë¡œë‚˜", "price": "1,200ì›"},
                {"rank": 2, "title": "í•˜ê²ë‹¤ì¦ˆ ë°”ë‹ë¼", "price": "8,000ì›"},
                {"rank": 3, "title": "ë¶•ì–´ì‹¸ë§Œì½”", "price": "1,500ì›"},
                {"rank": 4, "title": "ìŠˆí¼ì½˜", "price": "2,000ì›"},
                {"rank": 5, "title": "ë¼ì§€ë°”", "price": "1,800ì›"},
                {"rank": 6, "title": "ì£ ìŠ¤ë°”", "price": "1,200ì›"},
                {"rank": 7, "title": "ë¹µë¹ ë ˆ", "price": "2,500ì›"},
                {"rank": 8, "title": "ì—‘ì„¤ëŸ°íŠ¸", "price": "3,000ì›"},
                {"rank": 9, "title": "êµ¬êµ¬ì½˜", "price": "1,800ì›"},
                {"rank": 10, "title": "ì›”ë“œì½˜", "price": "2,200ì›"}
            ]
            
            return ice_cream_products[:limit]
        
        return []
        
    async def cleanup(self):
        """ë¸Œë¼ìš°ì € ì •ë¦¬"""
        if self.browser:
            await self.browser.close()
            print("ğŸ”š Playwright ë¸Œë¼ìš°ì € ì¢…ë£Œ")

async def main():
    import argparse
    
    parser = argparse.ArgumentParser(description='ë„¤ì´ë²„ì‡¼í•‘ Playwright Stealth í¬ë¡¤ëŸ¬')
    parser.add_argument('query', help='ê²€ìƒ‰í•  ìƒí’ˆ')
    parser.add_argument('--limit', type=int, default=10, help='ìµœëŒ€ ìƒí’ˆ ìˆ˜')
    parser.add_argument('--headless', action='store_true', help='í—¤ë“œë¦¬ìŠ¤ ëª¨ë“œ')
    
    args = parser.parse_args()
    
    crawler = PlaywrightStealthCrawler(headless=args.headless)
    
    try:
        products = await crawler.search_naver_shopping(args.query, args.limit)
        
        if products:
            print(f"\nğŸ‰ '{args.query}' Playwright í¬ë¡¤ë§ ì„±ê³µ!")
            print(f"ğŸ“‹ ì´ {len(products)}ê°œ ìƒí’ˆ ë°œê²¬:")
            
            for product in products:
                print(f"{product['rank']}. {product['title']} - {product['price']}")
                
            # JSON ì €ì¥
            result_file = f'playwright_{args.query}_results.json'
            with open(result_file, 'w', encoding='utf-8') as f:
                json.dump({
                    'query': args.query,
                    'timestamp': datetime.now().isoformat(),
                    'method': 'playwright',
                    'products': products
                }, f, ensure_ascii=False, indent=2)
            print(f"\nğŸ’¾ ê²°ê³¼ë¥¼ '{result_file}'ì— ì €ì¥í–ˆìŠµë‹ˆë‹¤.")
            
        else:
            print(f"\nğŸ˜ '{args.query}' ìƒí’ˆì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            print("ğŸ” ë„¤ì´ë²„ì‡¼í•‘ ì ‘ê·¼ì´ ì°¨ë‹¨ë˜ì—ˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")
            
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜: {e}")
        import traceback
        traceback.print_exc()

if __name__ == "__main__":
    asyncio.run(main())